\documentclass{article}
\usepackage[top=1in, bottom=1.25in, left=1in, right=1in]{geometry}
\usepackage{fontspec}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{alltt}
\usepackage[utf8]{luainputenc}
\usepackage[bibencoding=utf8,backend=biber]{biblatex}
\addbibresource{cosc6384.final.michael-yantosca.report.bib}
\usepackage{minted}
\usepackage{longtable}
\usepackage{enumerate}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{pgfgantt}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepgfplotslibrary{external}
\usepgfplotslibrary{statistics}
\usepgfplotslibrary{groupplots}
\usetikzlibrary{pgfplots.groupplots}
\pgfplotsset{
  tick label style={font=\footnotesize},
  label style={font=\small},
  legend style={font=\small},
  compat=newest
}
\pgfplotstableset{
  col sep=comma,
  begin table=\begin{longtable},
  end table=\end{longtable},
  every head row/.append style={after row=\endhead}
}
\usepgflibrary{arrows.meta}
\pagestyle{fancy}
\fancyhf{}
\rhead{Closing the Gap: Optimizing the Gap Enumeration Algorithm}
\lhead{Michael Yantosca}
\rfoot{\thepage}
\newcommand{\todo}[0]{\textbf{\textcolor{red}{TODO}}}
\algloopdefx{ExitWhile}[0]{\textbf{exit while}}
\algloopdefx{NewIf}[1]{\textcolor{red}{\textbf{if} #1 \textbf{then}}}
\algloopdefx{NewEndIf}[0]{\textcolor{red}{\textbf{end if}}}
\algloopdefx{NewElse}[0]{\textcolor{red}{\textbf{else}}}
\algblock{NewIf}{NewEndIf}
%\algblock{NewIf}{NewElse}{NewEndIf}
%\algloopdefx{NewState}[1]{\textcolor{red}{ #1 }}

\pgfplotstableread{./results/taskset-n3-m500-optimization1-1gap.csv}\tasksAa
\pgfplotstableread{./results/taskset-n5-m500-optimization1-1gap.csv}\tasksBa
\pgfplotstableread{./results/taskset-n7-m500-optimization1-1gap.csv}\tasksCa
\pgfplotstableread{./results/taskset-n3-m500-optimization2-1gap.csv}\tasksAb
\pgfplotstableread{./results/taskset-n5-m500-optimization2-1gap.csv}\tasksBb
\pgfplotstableread{./results/taskset-n7-m500-optimization2-1gap.csv}\tasksCb


\begin{document}

\tableofcontents

\begin{section}{Abstract}
  Functional Reactive Programming (FRP) offers an attractive alternative to traditional
  real-time programming paradigms on account of its inherent atomicity by function call,
  which can simplify the process of static analysis through stronger invariants.
  However, these guarantees come at the price of a more complicated timing analysis
  required by the Abort-And-Restart (ANR) scheduling method which Priority-Based FRP
  (P-FRP) employs and which provides the underpinning for the aforementioned atomicity.
  Earlier work by Chaitanya Belwal and Albert M. K. Cheng developed and explored the
  gap-enumeration algorithm, a method for characterizing the worst case response time (WCRT)
  of each task in a set of tasks under the ANR model that outperformed time-accurate simulation
  in terms of efficiency. Here the work is revisited with the aim of further optimizing the
  performance of the gap-enumeration algorithm
\end{section}

\begin{section}{Introduction}
\end{section}

\begin{section}{Methodology}
  \begin{subsection}{Implementing the Original Algorithm}
    \begin{paragraph}{}
      The original gap-enumeration algorithm is given below with some slight modifications
      for clarity.

    \begin{algorithm}[H]
      \caption{Gap-Enumeration Algorithm\autocite[11]{BelwalCheng}}\label{gapenum1}
      \begin{algorithmic}[1]
        \Function{Gap-Enumerate-Dynamic}{$\Gamma_{n}$, $\tau_{j}$, $w$}
          \State $L \gets \lceil\frac{P_{j}}{w}\rceil$
          \State $U \gets P_{j} + \lceil\frac{P_{j}}{w}\rceil$
          \While{$L < U$}
            \State $\sigma_{n}(P|_{0}^{L}) \gets \{[0,L)\}$
            \For{$i \gets n-1,j$}
              \State $\sigma_{i-1}(P|_{0}^{L}) \gets \Call{Gap-Transform}{L, \sigma_{i}(P|_{0}^{L}), \Gamma_{n}, j}$
              \If{$\sigma_{i-1}(P|_{0}^{L}) = \emptyset$}
                \State \Return -1
              \EndIf
            \EndFor
            \State $[t_{1},t_{2}) \gets \Call{Gap-Search}{\sigma_{j}(P|_{0}^{L}), C_{j}}$
            \If{$t_{1} \geq 0$}
              \State $RT_{j} \gets t_{1} + C_{j}$
            \EndIf
            \If{$RT_{j} < P_{j}$}
              \State \Return $RT_{j}$
            \EndIf
            \State $L \gets L + \lceil\frac{P_{j}}{w}\rceil$
          \EndWhile
        \State \Return -1
      \EndFunction
      \end{algorithmic}
    \end{algorithm}

    The original work set the post-search $t_{1}$ validity test as $t_{1} > 0$, but
    this precludes scheduling work at $t = 0$, so the test $t_{1} \geq 0$
    was substituted.
    \end{paragraph}

    \begin{paragraph}{}
      The original gap-transformation algorithm is given below with some slight
      modifications for clarity as necessitated by implementation details.

    \begin{algorithm}[H]
      \caption{Gap-Tranformation Algorithm\autocite[12]{BelwalCheng}}\label{gapxfrm1}
      \begin{algorithmic}[2]
        \Function{Gap-Transform}{$W$, $\sigma_{i}(P|_{0}^{L})$, $\Gamma_{n}$, $j$}
          \State $J_{i} \gets \lceil\frac{W - R_{j}}{P_{j}}\rceil$
          \For{$q \gets 1, J_{i}$}
            \State $t \gets R_{j} + P_{j}(q-1)$
            \State $kgap \gets \Call{Min-Gap}{\sigma_{i}(P|_{0}^{L})}$
            \State $t_{1} \gets \Call{Entry}{kgap}$
            \State $t_{2} \gets \Call{Exit}{kgap}$
            \While{$kgap \not= \Call{Nil}{\sigma_{i}(P|_{0}^{L})}$}
              \If{$t_{1} > t + P_{j}$}
                \State \Return $\emptyset$
              \EndIf
              \If{$t < t_{1}$}
                \State $t \gets t_{1}$
              \EndIf
              \If{$t_{1} \leq t$ and $t < t_{2}$}
                \State \Call{Gap-Delete}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t_{2})$}
                \If{$t + C_{j} = t_{2}$}
                  \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t)$}
                  \ExitWhile
                \EndIf
                \If{$t + C_{j} < t_{2}$}
                  \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t)$}
                  \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t + C_{j},t_{2})$}
                  \ExitWhile
                \EndIf
                \If{$t + C_{j} > t_{2}$}
                  \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t)$}
                \EndIf
              \EndIf
              \If{$t1 = \Call{Entry}{kgap}$}
                \State $kgap \gets \Call{Successor-Gap}{t_{1}}$
              \EndIf
            \EndWhile
          \EndFor
          \State $\sigma_{i-1}(P|_{0}^{L}) \gets \sigma_{i}(P|_{0}^{L})$
          \State \Return $\sigma_{i-1}(P|_{0}^{L})$
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    \end{paragraph}
    \begin{paragraph}{}
      Note that the test before performing an advance along the tree is required
      since in the case where the $k$-gap is filled with slack at the end, the
      reinserted node whose entry time is $t + C_{j}$ must not be skipped in the
      gap traversal.
    \end{paragraph}
  \end{subsection}

  \begin{subsection}{Task Set Generation}
    \begin{paragraph}{}
      Task set generation generally followed the parameters outlined in the original work\autocite[14]{BelwalCheng}.
      Tasks were randomly generated in 3 groups ($A$, $B$, and $C$) where group $A$ was
      comprised of sets with 3 tasks, group $B$ with sets of 5 tasks, and group $C$ with
      sets of 7 tasks. All tasks were implicit-deadline and implicit-priority, i.e.,
      the deadline was implicitly defined as equal to the task release period,
      and the priority was implicitly defined as the task period with higher priority
      given to tasks with smaller periods. The prioritization of tasks in this way is
      required in order for the gap-enumeration algorithm to work and correctly model
      the behavior of the P-FRP scheduler.
    \end{paragraph}
    \begin{paragraph}{}
      Task periods were randomly distributed over a uniform distribution within the
      interval ${[}40,60{)}$ by means of the \texttt{std::uniform\_int\_distribution}
      facility of the C++ language\autocite{stduniformintdist}. The distribution
      was generated by of the
      \texttt{std::shuffle\_order\_engine}\autocite{stdshuffleorderengine} pseudo-random
      number generator (PRNG) with the parameters of the default provided \texttt{knuth\_b}
      instance seeded by the nanosecond epoch time immediately prior to the instantiation
      of the PRNG.
    \end{paragraph}
    \begin{paragraph}{}
      Task computation times were randomly distributed over the interval ${[}4,10{)}$
      in the same manner using an independent distribution and PRNG. The distributions
      were queried over a series of iterations of two nested loops, the outer loop
      spanning the population of task sets and the inner loop spanning the task set size.
      As each task set was constructed, the tasks were sorted in increasing order by
      priority, i.e., most urgent and frequent task first, with ties broken by
      computation time in decreasing order thereof.
    \end{paragraph}
    \begin{paragraph}{}
      Within a task set population, each task set was unique in terms of the task
      set serialization. This is to say that the shell command
      \begin{alltt}
        wc -l \$TASKSETFILE
      \end{alltt}
      yielded the same results as
      \begin{alltt}
        sort \$TASKSETFILE | uniq | wc -l
      \end{alltt}
      Since each task set was deterministically sorted first by priority and then by
      computation time, the uniqueness of the string serialization of the task set is
      equivalent to the uniqueness of the task set itself.
    \end{paragraph}
  \end{subsection}

  \begin{subsection}{Optimization 1}
    \begin{paragraph}{}
      Having implemented the original algorithm, it became clear that the constant
      deletion and reinsertion costs were a major component of the algorithm's
      computational cost, validating conclusions drawn in the original work\autocite[17]{BelwalCheng}. However, rather than devising a space-costly indexing scheme to try and speed
      up the tree modification operations, it was determined that a less expensive
      adjustment might yield even better efficiency after observing that the original
      algorithm reinserted a $k$-gap of size zero (0) back into the tree after a job
      had been scheduled into a gap either for a completed or aborted execution.
      Since these null gaps could never fit a task in following iterations of the
      gap-transformation function, including them in the tree incurred extraneous costs.
    \end{paragraph}
    \begin{paragraph}{}
      Consequently, modifications were made to perform a size check
      on $k$-gaps prior to reinsertion to prevent null gaps from being introduced
      as outlined in the following algorithm. The changes in the algorithm are
      highlighted in red for legibility.
    \begin{algorithm}[H]
      \caption{Gap-Tranformation Algorithm Optimization 1: No Zero Gaps Reinserted}\label{gapxfrm2}
      \begin{algorithmic}[2]
        \Function{Gap-Transform-Positive}{$W$, $\sigma_{i}(P|_{0}^{L})$, $\Gamma_{n}$, $j$}
          \State $J_{i} \gets \lceil\frac{W - R_{j}}{P_{j}}\rceil$
          \For{$q \gets 1, J_{i}$}
            \State $t \gets R_{j} + P_{j}(q-1)$
            \State $kgap \gets \Call{Min-Gap}{\sigma_{i}(P|_{0}^{L})}$
            \State $t_{1} \gets \Call{Entry}{kgap}$
            \State $t_{2} \gets \Call{Exit}{kgap}$
            \While{$kgap \not= \Call{Nil}{\sigma_{i}(P|_{0}^{L})}$}
              \If{$t_{1} > t + P_{j}$}
                \State \Return $\emptyset$
              \EndIf
              \If{$t < t_{1}$}
                \State $t \gets t_{1}$
              \EndIf
              \If{$t_{1} \leq t$ and $t < t_{2}$}
                \State \Call{Gap-Delete}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t_{2})$}
                \If{$t + C_{j} = t_{2}$}
                  \NewIf{$t > t_{1}$}
                    \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t)$}
                  \NewEndIf
                  \ExitWhile
                \EndIf
                \If{$t + C_{j} < t_{2}$}
                    \NewIf{$t > t_{1}$}
                      \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t)$}
                    \NewEndIf
                  \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t + C_{j},t_{2})$}
                  \ExitWhile
                \EndIf
                \If{$t + C_{j} > t_{2}$}
                  \NewIf{$t > t_{1}$}
                    \State \Call{Gap-Insert}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t)$}
                  \NewEndIf
                \EndIf
              \EndIf
              \If{$t1 = \Call{Entry}{kgap}$}
                \State $kgap \gets \Call{Successor-Gap}{t_{1}}$
              \EndIf
            \EndWhile
          \EndFor
          \State $\sigma_{i-1}(P|_{0}^{L}) \gets \sigma_{i}(P|_{0}^{L})$
          \State \Return $\sigma_{i-1}(P|_{0}^{L})$
        \EndFunction
      \end{algorithmic}
    \end{algorithm}
    \end{paragraph}
  \end{subsection}

  \begin{subsection}{Optimization 2}
    Converting to linked-list for O(1) insertion/deletion
    \begin{algorithm}[H]
      \caption{Gap-Tranformation Algorithm Optimization 2: No Zero Gaps Reinserted, Linked List}\label{gapxfrm2}
      \begin{algorithmic}[2]
        \Function{Gap-Transform-Positive-List}{$W$, $\sigma_{i}(P|_{0}^{L})$, $\Gamma_{n}$, $j$}
          \State $J_{i} \gets \lceil\frac{W - R_{j}}{P_{j}}\rceil$
          \For{$q \gets 1, J_{i}$}
            \State $t \gets R_{j} + P_{j}(q-1)$
            \State $kgap \gets \Call{Head}{\sigma_{i}(P|_{0}^{L})}$
            \State $t_{1} \gets \Call{Entry}{kgap}$
            \State $t_{2} \gets \Call{Exit}{kgap}$
            \While{$kgap \not= \Call{Tail}{\sigma_{i}(P|_{0}^{L})}$}
              \If{$t_{1} > t + P_{j}$}
                \State \Return $\emptyset$
              \EndIf
              \If{$t < t_{1}$}
                \State $t \gets t_{1}$
              \EndIf
              \If{$t_{1} \leq t$ and $t < t_{2}$}
                \If{$t + C_{j} \geq t_{2}$}
                  \If{$t > t_{1}$}
                    \State {$[t_{1},t_{2}) \gets [t_{1},t)$}
                  \Else
                    \State {\Call{Splice-Out}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t_{2})$}}
                  \EndIf
                  \If{$t + C_{j} = t_{2}$}
                    \ExitWhile
                  \EndIf
                \EndIf
                \If{$t + C_{j} < t_{2}$}
                    \State {$[t_{1},t_{2}) \gets [t + C_{j},t_{2})$}
                    \If{$t > t_{1}$}
                      \State \Call{Splice-In}{$\sigma_{i}(P|_{0}^{L}), [t_{1},t)$}
                    \EndIf
                  \ExitWhile
                \EndIf
              \EndIf
              \If{$t1 = \Call{Entry}{kgap}$}
                \State $kgap \gets \Call{Next}{t_{1}}$
              \EndIf
            \EndWhile
          \EndFor
          \State $\sigma_{i-1}(P|_{0}^{L}) \gets \sigma_{i}(P|_{0}^{L})$
          \State \Return $\sigma_{i-1}(P|_{0}^{L})$
        \EndFunction
      \end{algorithmic}
      \end{algorithm}
  \end{subsection}

\end{section}

\begin{section}{Results}

  \begin{subsection}{Original Method vs. Optimization 1}
    \begin{tikzpicture}
      \begin{groupplot}[
          group style={
            group size=3 by 1,
            xlabels at=edge bottom,
            ylabels at=edge left
          },
          width=2in,
          height=2in,
          xlabel=Task Set Number,
          ylabel=Computational Steps,
          legend style={legend columns=-1}
        ]
        \nextgroupplot[
          title={Task Set Group A ($n = 3$)},
          scatter, only marks, scatter src=explicit symbolic,
          scatter/classes={
            gapenum1={mark=o,blue},
            gapenum2={mark=o,red}
          },
          legend entries={Original, Optimization 1},
          legend to name=version
        ]
        \addplot table [x=m,y=steps,meta=version] {\tasksAa};
        \nextgroupplot[
          title={Task Set Group B ($n = 5$)},
          scatter, only marks, scatter src=explicit symbolic,
          scatter/classes={
            gapenum1={mark=o,blue},
            gapenum2={mark=o,red}
          },
          legend entries={Original, Optimization 1},
          legend to name=version
        ]
        \addplot table [x=m,y=steps,meta=version] {\tasksBa};
        \nextgroupplot[
          title={Task Set Group C ($n = 7$)},
          scatter, only marks, scatter src=explicit symbolic,
          scatter/classes={
            gapenum1={mark=o,blue},
            gapenum2={mark=o,red}
          },
          legend entries={Original, Optimization 1},
          legend to name=version
        ]
        \addplot table [x=m,y=steps,meta=version] {\tasksCa};
      \end{groupplot}
      \node at (4,-1.5) {\pgfplotslegendfromname{version}};
    \end{tikzpicture}
  \end{subsection}

  \begin{subsection}{Original Method vs. Optimization 2}
    \begin{tikzpicture}
      \begin{groupplot}[
          group style={
            group size=3 by 1,
            xlabels at=edge bottom,
            ylabels at=edge left
          },
          width=2in,
          height=2in,
          xlabel=Task Set Number,
          ylabel=Computational Steps,
          legend style={legend columns=-1}
        ]
        \nextgroupplot[
          title={Task Set Group A ($n = 3$)},
          scatter, only marks, scatter src=explicit symbolic,
          scatter/classes={
            gapenum1={mark=o,blue},
            gapenum2={mark=o,red}
          },
          legend entries={Original, Optimization 2},
          legend to name=version2
        ]
        \addplot table [x=m,y=steps,meta=version] {\tasksAb};
        \nextgroupplot[
          title={Task Set Group B ($n = 5$)},
          scatter, only marks, scatter src=explicit symbolic,
          scatter/classes={
            gapenum1={mark=o,blue},
            gapenum2={mark=o,red}
          },
          legend entries={Original, Optimization 2},
          legend to name=version2
        ]
        \addplot table [x=m,y=steps,meta=version] {\tasksBb};
        \nextgroupplot[
          title={Task Set Group C ($n = 7$)},
          scatter, only marks, scatter src=explicit symbolic,
          scatter/classes={
            gapenum1={mark=o,blue},
            gapenum2={mark=o,red}
          },
          legend entries={Original, Optimization 2},
          legend to name=version2
        ]
        \addplot table [x=m,y=steps,meta=version] {\tasksCb};
      \end{groupplot}
      \node at (4,-1.5) {\pgfplotslegendfromname{version2}};
    \end{tikzpicture}
  \end{subsection}
\end{section}

\begin{section}{Conclusions}
\end{section}

\begin{section}{Acknowledgments}
  \begin{paragraph}{}
    The author would like to thank Dr. Albert M. K. Cheng for his introduction to the original work by Chaitanya Belwal and himself.
  \end{paragraph}
\end{section}

\printbibliography

\begin{section}{Supplemental Material}
\end{section}
\end{document}
